{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izmeeJoOrkTt"
      },
      "source": [
        "# Run GLM-4.5 model on Nebius AI Studio\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nebius/ai-studio-cookbook/blob/main/models/glm4.5_1.ipynb)\n",
        "[![](https://img.shields.io/badge/Powered%20by-Nebius-orange?style=flat&labelColor=darkblue&color=orange)](https://nebius.com/ai-studio)\n",
        "\n",
        "**zai-org/GLM-4.5** model is a top performing open source model.  It comes in 'thinking' and 'instruct' variants.  Use this notebook to run this model on Nebius AI Studio.\n",
        "\n",
        "[Read more here](https://github.com/nebius/ai-studio-cookbook/blob/main/models/qwen3-2507.md)\n",
        "\n",
        "## References\n",
        "\n",
        "- Model card : [zai-org/GLM-4.5](https://huggingface.co/zai-org/GLM-4.5)\n",
        "- Model card for 'air' version: [zai-org/GLM-4.5-Air](https://huggingface.co/zai-org/GLM-4.5-Air)\n",
        "- [Nebius AI Studio](https://studio.nebius.com/)\n",
        "\n",
        "## Pre requisites\n",
        "\n",
        "- Nebius API key.  Sign up for free at [AI Studio](https://studio.nebius.com/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3KSn4LIvFo0"
      },
      "source": [
        "## 1 - Getting Started\n",
        "\n",
        "### 1.1 - Get your Nebius API key at [Nebius AI Studio](https://studio.nebius.com/)\n",
        "\n",
        "### 1.2 - If running on Google Colab ...\n",
        "\n",
        "Add `NEBIUS_API_KEY` to **Secrets** panel on the left as follows\n",
        "\n",
        "![](https://github.com/nebius/ai-studio-cookbook/raw/main/images/google-colab-1.png)\n",
        "\n",
        "\n",
        "### 1.3 - If running locally\n",
        "\n",
        "Create an `.env` file with NEBIUS_API_KEY as follows\n",
        "\n",
        "```text\n",
        "NEBIUS_API_KEY=your_api_key_goes_here\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJ-WCDSEy0G"
      },
      "source": [
        "## 2 - Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OTElVQApE9I7"
      },
      "outputs": [],
      "source": [
        "%pip install -q openai python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp6woeSsFGo5"
      },
      "source": [
        "## 2 - Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFSX16IeFLKa",
        "outputId": "695608c3-c61f-4502-828a-0ac603d04fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Colab\n",
            "✅ NEBIUS_API_KEY found\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "## Recommended way of getting configuration\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   from google.colab import userdata\n",
        "   NEBIUS_API_KEY = userdata.get('NEBIUS_API_KEY')\n",
        "else:\n",
        "   print(\"NOT running in Colab\")\n",
        "\n",
        "   from dotenv import load_dotenv\n",
        "   load_dotenv()\n",
        "   NEBIUS_API_KEY = os.getenv('NEBIUS_API_KEY')\n",
        "\n",
        "\n",
        "## quick hack (not recommended) - you can hardcode the config key here\n",
        "# NEBIUS_API_KEY = \"your_key_here\"\n",
        "\n",
        "if NEBIUS_API_KEY:\n",
        "  print ('✅ NEBIUS_API_KEY found')\n",
        "  os.environ['NEBIUS_API_KEY'] = NEBIUS_API_KEY\n",
        "else:\n",
        "  raise RuntimeError ('❌ NEBIUS_API_KEY NOT found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smYPQAlBtgTQ"
      },
      "source": [
        "## 3 - Run the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c67AElPbzP7z"
      },
      "source": [
        "### 3.1 - Initialize the client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Bx3BAsiIxfqi"
      },
      "outputs": [],
      "source": [
        "## Create a client\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
        "    api_key=os.environ.get('NEBIUS_API_KEY')\n",
        ")\n",
        "\n",
        "## Select a model\n",
        "MODEL_NAME = \"zai-org/GLM-4.5\" #\n",
        "#MODEL_NAME = \"zai-org/GLM-4.5-Air\" # lighter model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbKjxJndzT6r"
      },
      "source": [
        "### 3.2 - Find out the model's capabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1gN-e3Iw9H3",
        "outputId": "02d84b57-c583-483d-a027-9b3c35c7d63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----model answer -----\n",
            "I'm an AI assistant with a range of capabilities designed to help with various tasks:\n",
            "\n",
            "**Information & Knowledge:**\n",
            "- Answer questions on diverse topics including science, history, technology, and more\n",
            "- Explain complex concepts in simpler terms\n",
            "- Provide summaries of information on subjects you're interested in\n",
            "\n",
            "**Writing & Communication:**\n",
            "- Help draft, edit, and refine written content\n",
            "- Assist with creative writing, emails, reports, and other documents\n",
            "- Brainstorm ideas for projects or content\n",
            "- Improve grammar, style, and clarity in writing\n",
            "\n",
            "**Problem-Solving & Analysis:**\n",
            "- Break down complex problems\n",
            "- Compare and analyze information\n",
            "- Help with decision-making by presenting options\n",
            "- Assist with basic math and logical reasoning\n",
            "\n",
            "**Technical Assistance:**\n",
            "- Help with coding questions and debugging\n",
            "- Explain programming concepts\n",
            "- Assist with technical documentation\n",
            "\n",
            "**Language & Learning:**\n",
            "- Aid with language translation and learning\n",
            "- Explain vocabulary and grammar\n",
            "- Help create study materials and learning strategies\n",
            "\n",
            "I should note that I have limitations too - I don't have real-time information unless browsing is specifically enabled, I can't perform physical tasks, and I shouldn't replace professional advice in specialized fields like medicine or law.\n",
            "\n",
            "What would you like help with today?\n",
            "CPU times: user 10.1 ms, sys: 104 µs, total: 10.2 ms\n",
            "Wall time: 10.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model = MODEL_NAME,\n",
        "  messages=[\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You are a helpful AI assistant\"\n",
        "      },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What are your capabilities?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print ('----model answer -----')\n",
        "print (completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfeT8JxlzaNm"
      },
      "source": [
        "### 3.3 - Ask a factual question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8htBO7iH6-e",
        "outputId": "2b6c7ace-acaa-4fe9-aa01-1bda90779925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----model answer -----\n",
            "The capital of France is Paris.\n",
            "\n",
            "----- full response ----\n",
            "{\n",
            "  \"id\": \"chatcmpl-66476152779940f8894157b05a09a948\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"The capital of France is Paris.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"annotations\": null,\n",
            "        \"audio\": null,\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": [],\n",
            "        \"reasoning_content\": \"This is a straightforward factual question about the capital of France. The capital of France is Paris, which has been the capital city for many centuries and is the country's largest city. I'll provide a clear and direct answer.\"\n",
            "      },\n",
            "      \"stop_reason\": 151336\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1754687831,\n",
            "  \"model\": \"zai-org/GLM-4.5\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 56,\n",
            "    \"prompt_tokens\": 20,\n",
            "    \"total_tokens\": 76,\n",
            "    \"completion_tokens_details\": null,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null,\n",
            "  \"kv_transfer_params\": null\n",
            "}\n",
            "---------\n",
            "CPU times: user 3.57 ms, sys: 1.77 ms, total: 5.34 ms\n",
            "Wall time: 1.28 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model = MODEL_NAME,\n",
        "  messages=[\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You are a helpful AI assistant\"\n",
        "      },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is the capital of France?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print ('----model answer -----')\n",
        "print (completion.choices[0].message.content)\n",
        "print ('\\n----- full response ----')\n",
        "print(completion.to_json())\n",
        "print ('---------')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp2JEfLYzgEC"
      },
      "source": [
        "### 3.4 - Ask a reasoning question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5KlDwxJjhEX",
        "outputId": "5e7df624-0dcd-400c-f334-59531387544a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To determine which number is bigger between 9.9 and 9.11, we need to compare their decimal parts carefully, as both share the same whole number part (9).\n",
            "\n",
            "- 9.9 can be written as 9.90 (adding a zero to make it easier to compare with two decimal places).\n",
            "- 9.11 is already expressed with two decimal places.\n",
            "\n",
            "Now, compare the decimal parts:\n",
            "- 9.90 has a decimal part of 0.90 (which is 90 hundredths).\n",
            "- 9.11 has a decimal part of 0.11 (which is 11 hundredths).\n",
            "\n",
            "Since 90 hundredths is greater than 11 hundredths (0.90 > 0.11), it follows that 9.90 > 9.11, and therefore **9.9 is bigger than 9.11**.\n",
            "\n",
            "### Why this might be confusing:\n",
            "Sometimes people mistakenly think that 9.11 is larger because \"11\" is greater than \"9\" when ignoring the decimal point. However, in decimal notation, the place value matters:\n",
            "- In 9.9, the digit 9 is in the tenths place, meaning it represents 9/10 or 0.9.\n",
            "- In 9.11, the digit 1 is in the tenths place (representing 1/10 or 0.1), and the second 1 is in the hundredths place (representing 1/100 or 0.01).\n",
            "\n",
            "Since the tenths place has a higher value than the hundredths place, 9.9 (with 9 tenths) is larger than 9.11 (with only 1 tenth and 1 hundredth). Even if we consider the hundredths, 9 tenths (90 hundredths) is still greater than 11 hundredths.\n",
            "\n",
            "### Additional verification:\n",
            "- **Subtraction method**: 9.9 - 9.11 = 0.79, which is positive, confirming that 9.9 is larger.\n",
            "- **Number line**: On a number line, 9.9 (or 9.90) is closer to 10.0 than 9.11, so it is to the right and thus larger.\n",
            "\n",
            "In summary, **9.9 is bigger than 9.11**.\n",
            "----------\n",
            "CPU times: user 7.64 ms, sys: 82 µs, total: 7.72 ms\n",
            "Wall time: 29.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# try another model\n",
        "completion = client.chat.completions.create(\n",
        "  model = MODEL_NAME,\n",
        "  messages=[\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Which is bigger, 9.9 or 9.11?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print (completion.choices[0].message.content)\n",
        "print ('----------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7JaLormtgTR"
      },
      "source": [
        "## 5 - Try Your Queries\n",
        "\n",
        "Go ahead and experiment with your queries.  Here are some to get you started.\n",
        "\n",
        "> Write python code to read a csv file\n",
        "\n",
        "> write a haiku about cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "poXPoPfOzomP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "studio-cookbook-1",
      "language": "python",
      "name": "studio-cookbook-1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}