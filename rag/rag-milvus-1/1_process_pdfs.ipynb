{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG With llama-index  + Milvus + Qwen - Part 1\n",
    "\n",
    "References\n",
    "\n",
    "- https://studio.nebius.com/\n",
    "- https://docs.llamaindex.ai/en/stable/examples/vector_stores/MilvusIndexDemo/\n",
    "- https://docs.llamaindex.ai/en/stable/api_reference/storage/vector_store/milvus/?h=milvusvectorstore#llama_index.vector_stores.milvus.MilvusVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found NEBIUS_API_KEY in environment, using it\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.getenv('NEBIUS_API_KEY'):\n",
    "    print (\"✅ Found NEBIUS_API_KEY in environment, using it\")\n",
    "else:\n",
    "    raise ValueError(\"❌ NEBIUS_API_KEY not found in environment. Please set it in .env file before running this script.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Read documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 545 chunks\n",
      "CPU times: user 12.2 s, sys: 158 ms, total: 12.4 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import pprint\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_dir = '../../data/10k',\n",
    ").load_data()\n",
    "\n",
    "print (f\"Loaded {len(documents)} chunks\")\n",
    "\n",
    "# print(\"Document [0].doc_id:\", documents[0].doc_id)\n",
    "# pprint.pprint (documents[0], indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Setup Embedding Model\n",
    "\n",
    "We have a choice of local embedding model (fast) or running it on the cloud\n",
    "\n",
    "If running locally:\n",
    "- choose smaller models\n",
    "- less accuracy but faster\n",
    "\n",
    "If running on the cloud\n",
    "- We can run large models (billions of params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Option 1: Running embedding models on Nebius cloud\n",
    "from llama_index.embeddings.nebius import NebiusEmbedding\n",
    "EMBEDDING_MODEL = 'Qwen/Qwen3-Embedding-8B'  # 8B params\n",
    "EMBEDDING_LENGTH = 4096  # Length of the embedding vector\n",
    "Settings.embed_model = NebiusEmbedding(\n",
    "                        model_name=EMBEDDING_MODEL,\n",
    "                        embed_batch_size=50,  # Batch size for embedding (default is 10)\n",
    "                        api_key=os.getenv(\"NEBIUS_API_KEY\") # if not specfified here, it will get taken from env variable\n",
    "                       )\n",
    "\n",
    "## Option 2: Running embedding models locally\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "# Settings.embed_model = HuggingFaceEmbedding(\n",
    "#     # model_name = 'sentence-transformers/all-MiniLM-L6-v2' # 23 M params\n",
    "#     model_name = 'BAAI/bge-small-en-v1.5'  # 33M params\n",
    "#     # model_name = 'Qwen/Qwen3-Embedding-0.6B'  # 600M params\n",
    "#     # model_name = 'BAAI/bge-en-icl'  # 7B params\n",
    "#     #model_name = 'intfloat/multilingual-e5-large-instruct'  # 560M params\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Connect to Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/my-stuff/projects/nebius/ai-studio-cookbook-1/rag/rag-milvus-1/.venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at schema.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sujee/my-stuff/projects/nebius/ai-studio-cookbook-1/rag/rag-milvus-1/.venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at common.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sujee/my-stuff/projects/nebius/ai-studio-cookbook-1/rag/rag-milvus-1/.venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at milvus.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sujee/my-stuff/projects/nebius/ai-studio-cookbook-1/rag/rag-milvus-1/.venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at rg.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sujee/my-stuff/projects/nebius/ai-studio-cookbook-1/rag/rag-milvus-1/.venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at feder.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sujee/my-stuff/projects/nebius/ai-studio-cookbook-1/rag/rag-milvus-1/.venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.27.2 is exactly one major version older than the runtime version 6.31.1 at msg.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sujee/my-stuff/projects/nebius/ai-studio-cookbook-1/rag/rag-milvus-1/.venv/lib/python3.13/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Milvus instance:  ./rag.db\n",
      "✅ Cleared collection : rag\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "DB_URI = './rag.db'  # For embedded instance\n",
    "COLLECTION_NAME = 'rag'\n",
    "\n",
    "milvus_client = MilvusClient(DB_URI)\n",
    "print (\"✅ Connected to Milvus instance: \", DB_URI)\n",
    "\n",
    "# if we already have a collection, clear it first\n",
    "if milvus_client.has_collection(collection_name = COLLECTION_NAME):\n",
    "    milvus_client.drop_collection(collection_name = COLLECTION_NAME)\n",
    "    print ('✅ Cleared collection :', COLLECTION_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected Llama-index to Milvus instance:  ./rag.db\n",
      "CPU times: user 17.3 ms, sys: 5.96 ms, total: 23.2 ms\n",
      "Wall time: 554 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# connect to vector db\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri = DB_URI ,\n",
    "    dim = EMBEDDING_LENGTH ,\n",
    "    collection_name = COLLECTION_NAME,\n",
    "    overwrite=True\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "print (\"✅ Connected Llama-index to Milvus instance: \", DB_URI )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Create Index and Save to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 23:20:37,445 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:20:44,626 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:20:51,232 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:20:57,390 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:02,770 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:08,161 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:12,936 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:18,637 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:25,015 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:30,860 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:36,920 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:42,771 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:48,807 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:21:55,170 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:22:01,386 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-08-13 23:22:03,877 - INFO - HTTP Request: POST https://api.studio.nebius.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created index: <llama_index.core.indices.vector_store.base.VectorStoreIndex object at 0x705a2b6c4050>\n",
      "✅ Saved index to db  ./rag.db\n",
      "CPU times: user 3.72 s, sys: 460 ms, total: 4.18 s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create an index\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "print (\"⚙️ Creating index from documents...\")\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n",
    "print (\"✅ Created index:\", index )\n",
    "print (\"✅ Saved index to db \", DB_URI )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-milvus-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
